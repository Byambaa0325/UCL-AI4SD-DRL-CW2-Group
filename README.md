# UCL-AI4SD-DRL-CW2-Group

Coursework 2: Robotic Behavioural Cloning from Images and Actuator Data

## How to Finalize Your Work

### Team Workflow

1. **Experiments**: Do all experimental work in your personal folder
2. **Finalization**: Update `notebooks/main_notebook.ipynb` with your finalized code
3. **Pull Request**: Create a PR with your changes (requires review)
4. **Main Branch**: `notebooks/main_notebook.ipynb` must always be runnable in the main branch
5. **Weekly Standups**: Main notebook is reviewed during weekly standups

### Accessing Team Google Drive

**Shared Drive**: [Team Google Drive](https://drive.google.com/drive/folders/1srJtkipN0KspydlyxwAw6lHXR5chhsrs?usp=sharing)

**From Google Colab**:
1. Go to "Shared with me" in Google Drive
2. Right-click the folder → "Add shortcut to drive"
3. Select "MyDrive" → "Add Shortcut"
4. Mount drive in Colab: `drive.mount('/content/gdrive')`

See [detailed guide](https://towardsdatascience.com/simplify-file-sharing-44bde79a8a18/#:~:text=To%20access%20a%20shared%20with,file%20you%20want%20to%20access.) for full instructions.

## Setup

### 1. Environment Setup

Create and activate conda environment:
```bash
conda create -n coursework2 python -y
conda activate coursework2
conda install ipykernel -y
python -m ipykernel install --user --name coursework2 --display-name "Python (coursework2)"
```

Install dependencies:

**For CPU-only (default):**
```bash
pip install -r requirements.txt
```

**For CUDA support (if you have an NVIDIA GPU):**
```bash
# Windows:
install-cuda.bat

# Linux/Mac:
bash install-cuda.sh

# Or manually:
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements-cuda.txt
```

### 2. Dataset Download

1. Download the dataset from: https://drive.google.com/file/d/1ss_1RZZzov2SdJsYI_mRTpo6VBMRK43O/view?usp=sharing
2. Extract the zip file to: `data/all_play_data_diverse/` (within the repository)
3. Place `transition_df.csv` in the same directory: `data/all_play_data_diverse/transition_df.csv` (included in the coursework zip)

**Expected structure:**
```
data/all_play_data_diverse/
├── all_play_data_diverse.h5  (required by preprocessing)
└── transition_df.csv
```

**Important**: After downloading, you need to configure `ROOT_PATH` (see Configuration Variables section below).

### 3. Configuration Variables

In `notebooks/main_notebook.ipynb`, set these variables before running:

**Before Cell 10** (add new cell or modify existing):
```python
from comp0188_cw2.config import ROOT_PATH
ROOT_PATH = "./data/all_play_data_diverse"  # Set to repo data directory
```

**Cell 6:**
- `COLLAB = False` (set to `True` for Google Colab)
- `LOCAL = False` (set to `True` for Local Env to install local dependencies)

**Cell 10:**
- `project_options.collab = COLLAB` (matches Cell 6)
- `project_options.debug = True` (use `False` for full dataset) 
  
For the code to be committed to the main notebook set debug = True and run your code

**Cell 15:**
- `RUN_PREPROCESSING = True` (set to `False` after first successful run)

### 4. Run Preprocessing

Execute Cell 15 to generate train/val/test splits. This step:
- Reads `all_play_data_diverse.h5` and `transition_df.csv`
- Creates `.h5` files in `data/all_play_data_diverse/debug/train/`, `val/`, and `test/`
- Removes trajectories longer than 75 timesteps

**Note:** Only run preprocessing once per dataset (debug and full).

## Project Structure

```
UCL-AI4SD-DRL-CW2-Group/
├── notebooks/
│   ├── main_notebook.ipynb      # Main coursework notebook
│   ├── eda_example.ipynb        # EDA template
│   └── eval_example.ipynb       # Evaluation template
├── data/
│   └── all_play_data_diverse/   # Dataset location
│       ├── all_play_data_diverse.h5    # Raw dataset file (gitignored)
│       ├── transition_df.csv            # Dataset metadata (gitignored)
│       └── debug/                       # Generated by preprocessing
│           ├── train/                   # Train split files (gitignored)
│           ├── val/                     # Validation split files (gitignored)
│           └── test/                    # Test split files (gitignored)
├── requirements.txt             # Python dependencies
├── README.md                    # This file
└── .gitignore                   # Git ignore rules
```

## Important Notes

- Set configuration variables (`COLLAB`, `project_options.debug`, `RUN_PREPROCESSING`) **before** loading other `comp0188_cw2` functionality
- Preprocessing must be run before loading data in Cell 18
- Use `project_options.debug = True` for faster iteration during development

## Appendix: Configuration

### Custom Data Path

The default data location is `./data/all_play_data_diverse/` (within the repository). To use this or change it, modify `ROOT_PATH` **before** importing other `comp0188_cw2` modules:

```python
from comp0188_cw2.config import ROOT_PATH
ROOT_PATH = "./data/all_play_data_diverse"  # Default: repo data directory
# OR for external location:
ROOT_PATH = "../data/all_play_data_diverse"  # External location

# Then import other modules
from comp0188_cw2.utils import load_all_files
# ... rest of imports
```

**Important**: Set `ROOT_PATH` immediately after importing `config`, before any other `comp0188_cw2` imports.

### Configuration Variables Reference

| Variable | Location | Default | Description |
|----------|----------|---------|-------------|
| `COLLAB` | Cell 6 | `False` | Set to `True` for Google Colab environment |
| `LOCAL` | Cell 6 | `False` | Set to `True` to install local dependencies |
| `project_options.collab` | Cell 10 | `COLLAB` | Matches `COLLAB` setting |
| `project_options.debug` | Cell 10 | `True` | `True` for debug subset, `False` for full dataset |
| `RUN_PREPROCESSING` | Cell 15 | `True` | Set to `False` after first successful preprocessing run |
| `ROOT_PATH` | Before Cell 10 | `./data/all_play_data_diverse` | Base path for dataset (modify before imports) |
